{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is supposed to perform an average resource allocation bipartite projection\n",
    "For reference please read the book. The projection is going to be made **onto hosts**, because we found that doing it on parasites poses problems with a) similarity b) creating an answerable hypothesis.\n",
    "\n",
    "Why do we use the average resource allocation to discount both for saturation problem and bandwidth problem.\n",
    "Bandwidth problem: when there is a very rare parasites, which feeds upon only these two animals there is an argument that these animals are more similar that animals sharing a parasite which feeds upon 1000 other species.\n",
    "Saturation problem: when these animals share 60% and 80% percent of parasites, there is an argument that these animals are more similar than animals sharing only 20% and 10% of animals.\n",
    "\n",
    "Why do we use average, not minimum or maximum?\n",
    "- minimum would mean taking the weight of directed link from the animal with lower share, maximum with greater. Minimum means that we can safely assume that both of them are ???? TO do - \n",
    "- average - ok, fine.\n",
    "I think taking the minimum could make sense because it guarantees that both species are similar of at least this bar to each other.\n",
    "But for now we go with average\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'Host', 'Parasite', 'ParasiteFull',\n",
       "       'group', 'locality', 'hostgroup', 'animal_nodes', 'parasites_nodes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./full_data.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I'm assigning every property to the host, such that after projection we loose no data.\n",
    "Remember:\n",
    "- animalis might be victims of multiple paragroups\n",
    "- animals are assigned to one hostgroup.\n",
    "- animals might be in multiple localities.\n",
    "- parasites are assigned to one hostgroup and one paragroup and multiple localities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "for i, el in df.iterrows():\n",
    "    if G.has_node(el['Parasite']):\n",
    "        G.add_node(el['Parasite'], bipartite=0)\n",
    "    if G.has_node(el['Host']):\n",
    "        G.nodes[el['Host']]['locality'].add(el['locality'])\n",
    "        G.nodes[el['Host']]['para_group'].add(el['group'])\n",
    "    else:\n",
    "        locality = set()\n",
    "        locality.add(el['locality'])\n",
    "        para_group = set()\n",
    "        para_group.add(el['group'])\n",
    "        G.add_node(el['Host'], bipartite=1, host_group=el['hostgroup'], para_group=para_group, locality=locality)\n",
    "    if not G.has_edge(el['Host'], el['Parasite']):\n",
    "        G.add_edge(el['Host'], el['Parasite'], )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5870\n"
     ]
    }
   ],
   "source": [
    "# average resource allocation bipartite projection for host nodes\n",
    "# ProbS you multiply the stochastic with a stochastic version of the transpose. then get (wu,v + wv,u)/2\n",
    "# code below:\n",
    "\n",
    "bipartite_one_nodes = [ n for n, d in G.nodes(data=True) if d.get('bipartite') == 1]\n",
    "print(len(bipartite_one_nodes))\n",
    "badj = nx.bipartite.biadjacency_matrix(G, row_order=sorted(bipartite_one_nodes)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row stochastic adjacency matrix, of going from host to parasite\n",
    "A = badj / badj.sum(axis=1)[:, np.newaxis]\n",
    "At = badj.T / badj.T.sum(axis=1)[:, np.newaxis]\n",
    "weights = A @ At"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "225108.0\n"
     ]
    }
   ],
   "source": [
    "# now we have directional weights, we need to get the average\n",
    "resource_allocation_weights = (weights + weights.T) / 2\n",
    "# sanity check: symmetric matrix\n",
    "print(np.allclose(resource_allocation_weights, resource_allocation_weights.T))\n",
    "# compute the number of edges\n",
    "print(np.count_nonzero(~np.isclose(resource_allocation_weights,0)) / 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5832543940993622)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(resource_allocation_weights[1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELF LOOPS, are we care about them? not much tbh, we can remove them later.\n",
    "We don't care - we need to remove them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# are there any nans in resource_allocation_weights?\n",
    "print(np.isnan(resource_allocation_weights).any())\n",
    "# are there any inf in resource_allocation_weights?\n",
    "print(np.isinf(resource_allocation_weights).any())\n",
    "# are there any rows that sum to zero? (contains only zeros)\n",
    "print(np.any(np.isclose(resource_allocation_weights.sum(axis=1), 0)))\n",
    "# are there any rows which have only one non-zero element?\n",
    "print(np.any(np.count_nonzero(resource_allocation_weights, axis=1) == 1))\n",
    "\n",
    "# are there rows not summing to 1?\n",
    "print(np.any(np.isclose(resource_allocation_weights.sum(axis=1), 1) == False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macie\\AppData\\Local\\Temp\\ipykernel_20684\\780204485.py:10: RuntimeWarning: divide by zero encountered in divide\n",
      "  edge_neighbourhood_weights_means = edge_neighbourhood_weights_sums / (np.count_nonzero(resource_allocation_weights, axis=1) - 1)[:, np.newaxis]\n",
      "C:\\Users\\macie\\AppData\\Local\\Temp\\ipykernel_20684\\780204485.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  edge_neighbourhood_weights_means = edge_neighbourhood_weights_sums / (np.count_nonzero(resource_allocation_weights, axis=1) - 1)[:, np.newaxis]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.67559975, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.08333333, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.07692308, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.33333333,\n",
       "        0.33333333],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.33333333,\n",
       "        0.33333333]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do the noise corrected disparity filter\n",
    "# You don't need to take care of zeros, because these are going to be zero anyway after the filtering\n",
    "\n",
    "\n",
    "node_edges_weights_sum = resource_allocation_weights.sum(axis=1)\n",
    "edge_neighbourhood_weights_sums = node_edges_weights_sum[:, np.newaxis] - resource_allocation_weights\n",
    "# are there rows that sum to zero? (contains only zeros)\n",
    "print(np.any(np.isclose(edge_neighbourhood_weights_sums.sum(axis=1), 0)))\n",
    "\n",
    "edge_neighbourhood_weights_means = edge_neighbourhood_weights_sums / (np.count_nonzero(resource_allocation_weights, axis=1) - 1)[:, np.newaxis]\n",
    "# there could be 0/0, which would result in nan, replace these with zeros\n",
    "# I don't understand how infs emerge, but they do, so replace them with zeros\n",
    "edge_neighbourhood_weights_means = np.nan_to_num(edge_neighbourhood_weights_means, nan=0, posinf=0, neginf=0)\n",
    "\n",
    "# above should not be symmetric\n",
    "print(np.allclose(edge_neighbourhood_weights_means, edge_neighbourhood_weights_means.T))\n",
    "disparity_filter = (edge_neighbourhood_weights_means + edge_neighbourhood_weights_means.T) / 2\n",
    "\n",
    "# where the values are below the disparity filter, set to zero\n",
    "filtered_weights = resource_allocation_weights.copy()\n",
    "# check if both disparity filter and resource_allocation_weights are symmetric\n",
    "print(np.allclose(disparity_filter, disparity_filter.T))\n",
    "print(np.allclose(resource_allocation_weights, resource_allocation_weights.T))\n",
    "filtered_weights[resource_allocation_weights < disparity_filter] = 0\n",
    "filtered_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# check if the filtered weights are symmetric\n",
    "print(np.allclose(filtered_weights, filtered_weights.T))\n",
    "# compute the number of values which are not close to zero\n",
    "print(np.count_nonzero(~np.isclose(filtered_weights, 0))/2)\n",
    "filtered_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtered weights is not symmetric, but has inconsistent amount of edges? :()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new undirected graph with the filtered weights as adjacency matrix\n",
    "G_filtered = nx.from_numpy_array(filtered_weights)\n",
    "# reassign the node names and attributes\n",
    "G_filtered = nx.relabel_nodes(G_filtered, dict(enumerate(bipartite_one_nodes)))\n",
    "# add the attributes\n",
    "for n, d in G.nodes(data=True):\n",
    "    if d.get('bipartite') == 1:\n",
    "        # drop the bipartite attribute\n",
    "        d.pop('bipartite')\n",
    "        G_filtered.nodes[n].update(d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
