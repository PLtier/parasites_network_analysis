{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we use average, not minimum or maximum?\n",
    "- minimum would mean taking the weight of directed link from the animal with lower share, maximum with greater. Minimum means that we can safely assume that both of them are ???? TO do - \n",
    "- average - ok, fine.\n",
    "I think taking the minimum could make sense because it guarantees that both species are similar of at least this bar to each other.\n",
    "But for now we go with average\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You project hosts onto parasites \n",
    "then, you want to answer if this projection was good?\n",
    "Maybe it's OK?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from networkx.algorithms import bipartite\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./full_data.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hostgroup'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I'm assigning every property to the host, such that after projection we loose no data.\n",
    "Remember:\n",
    "- animalis might be victims of multiple paragroups\n",
    "- animals are assigned to one hostgroup.\n",
    "- animals might be in multiple localities.\n",
    "- parasites are assigned to one hostgroup and one paragroup and multiple localities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#projection of parasites onto hosts\n",
    "#1-Mode projection\n",
    "from resource_allocation import obtain_parasites_graph\n",
    "\n",
    "G = obtain_parasites_graph(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "bipartite_1_nodes = [n for n, data in G.nodes(data=True) if data.get('bipartite') == 1]\n",
    "\n",
    "print(len(bipartite_1_nodes), bipartite_1_nodes)\n",
    "\n",
    "projected_G = bipartite.projected_graph(G, bipartite_1_nodes)\n",
    "\n",
    "print(len(projected_G.nodes(data=True)) ,len(projected_G.edges(data=True)))\n",
    "\n",
    "# Copy attributes from the original graph G to projected_G\n",
    "for node in projected_G.nodes():\n",
    "    if node in G.nodes():\n",
    "        # Copy all attributes of the node from the original graph\n",
    "        projected_G.nodes[node].update(G.nodes[node])\n",
    "\n",
    "# Save the graph to a file\n",
    "with open('projected_graph_para.gpickle', 'wb') as f:\n",
    "    pickle.dump(projected_G, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projection of parasites onto hosts (hosts remain)\n",
    "G = nx.Graph()\n",
    "\n",
    "for i, el in df.iterrows():\n",
    "    if G.has_node(el['Parasite']):\n",
    "        G.add_node(el['Parasite'], bipartite=0)\n",
    "    if G.has_node(el['Host']):\n",
    "        G.nodes[el['Host']]['locality'].add(el['locality'])\n",
    "        G.nodes[el['Host']]['para_group'].add(el['group'])\n",
    "    else:\n",
    "        locality = set()\n",
    "        locality.add(el['locality'])\n",
    "        para_group = set()\n",
    "        para_group.add(el['group'])\n",
    "        G.add_node(el['Host'], bipartite=1, host_group=el['hostgroup'], para_group=para_group, locality=locality)\n",
    "    if not G.has_edge(el['Host'], el['Parasite']):\n",
    "        G.add_edge(el['Host'], el['Parasite'], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(dict(projected_G.degree()).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(graph):\n",
    "    graph_degrees=dict(graph.degree()).values()\n",
    "    stats_dict={}\n",
    "    #average degree\n",
    "    stats_dict[\"average_degree\"]=sum(graph_degrees)/graph.number_of_nodes()\n",
    "    #max degree\n",
    "    stats_dict[\"max_degree\"]=max(graph_degrees)\n",
    "    #min degree\n",
    "    stats_dict[\"min_degree\"]=min(graph_degrees)\n",
    "    #percentage under the average\n",
    "    stats_dict[\"percentage_under_average\"]=len([d for d in graph_degrees if d < stats_dict[\"average_degree\"]])/len(graph_degrees)\n",
    "    #assortativity\n",
    "    stats_dict[\"degree_assortativity\"]=nx.degree_assortativity_coefficient(graph)\n",
    "    #modularity\n",
    "    communities = nx.community.greedy_modularity_communities(graph)\n",
    "    stats_dict[\"modularity\"]=nx.community.modularity(graph,communities)\n",
    "    #...\n",
    "    return stats_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=stats(projected_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('stats/1-mode projection.txt', 'w+') as convert_file: \n",
    "     convert_file.write(json.dumps(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have directional weights, we need to get the average\n",
    "from resource_allocation import average_resource_allocation\n",
    "from resource_allocation import obtain_bipartite_animals_parasites_graph\n",
    "\n",
    "badj, names = obtain_bipartite_animals_parasites_graph(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maciej\\AppData\\Local\\Temp\\ipykernel_28604\\302908645.py:1: RuntimeWarning: invalid value encountered in divide\n",
      "  np.array([0])/np.int16(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([0])/np.int16(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maciej\\AppData\\Local\\Temp\\ipykernel_28604\\3967807711.py:1: RuntimeWarning: invalid value encountered in divide\n",
      "  A = badj / badj.sum(axis=1)[:, np.newaxis]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "A = badj / badj.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06535948, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.26136364, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.11666667, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.05631868, 0.03846154,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.03846154, 0.28846154,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resource_allocation_weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(resource_allocation_weights - resource_allocation_weights.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m \u001b[0maverage_resource_allocation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbadj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;32min\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;32min\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m ddd\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\maciej\\projects\\parasites_network_analysis\\resource_allocation.py\n",
      "\u001b[1;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "?average_resource_allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "528861.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "resource_allocation_weights = average_resource_allocation(badj)\n",
    "\n",
    "\n",
    "\n",
    "# sanity check: symmetric matrix\n",
    "print(np.allclose(resource_allocation_weights, resource_allocation_weights.T))\n",
    "# compute the number of edges\n",
    "print(np.count_nonzero(~np.isclose(resource_allocation_weights,0)) / 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(resource_allocation_weights[1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELF LOOPS, are we care about them? not much tbh, we can remove them later.\n",
    "We don't care - we need to remove them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# are there any nans in resource_allocation_weights?\n",
    "print(np.isnan(resource_allocation_weights).any())\n",
    "# are there any inf in resource_allocation_weights?\n",
    "print(np.isinf(resource_allocation_weights).any())\n",
    "# are there any rows that sum to zero? (contains only zeros)\n",
    "print(np.any(np.isclose(resource_allocation_weights.sum(axis=1), 0)))\n",
    "# are there any rows which have only one non-zero element?\n",
    "print(np.any(np.count_nonzero(resource_allocation_weights, axis=1) == 1))\n",
    "\n",
    "# are there rows not summing to 1?\n",
    "print(np.any(np.isclose(resource_allocation_weights.sum(axis=1), 1) == False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the noise corrected disparity filter\n",
    "# You don't need to take care of zeros, because these are going to be zero anyway after the filtering\n",
    "\n",
    "\n",
    "node_edges_weights_sum = resource_allocation_weights.sum(axis=1)\n",
    "edge_neighbourhood_weights_sums = node_edges_weights_sum[:, np.newaxis] - resource_allocation_weights\n",
    "# are there rows that sum to zero? (contains only zeros)\n",
    "print(np.any(np.isclose(edge_neighbourhood_weights_sums.sum(axis=1), 0)))\n",
    "\n",
    "edge_neighbourhood_weights_means = edge_neighbourhood_weights_sums / (np.count_nonzero(resource_allocation_weights, axis=1) - 1)[:, np.newaxis]\n",
    "# there could be 0/0, which would result in nan, replace these with zeros\n",
    "# I don't understand how infs emerge, but they do, so replace them with zeros\n",
    "edge_neighbourhood_weights_means = np.nan_to_num(edge_neighbourhood_weights_means, nan=0, posinf=0, neginf=0)\n",
    "\n",
    "# above should not be symmetric\n",
    "print(np.allclose(edge_neighbourhood_weights_means, edge_neighbourhood_weights_means.T))\n",
    "disparity_filter = (edge_neighbourhood_weights_means + edge_neighbourhood_weights_means.T) / 2\n",
    "\n",
    "# where the values are below the disparity filter, set to zero\n",
    "filtered_weights = resource_allocation_weights.copy()\n",
    "# check if both disparity filter and resource_allocation_weights are symmetric\n",
    "print(np.allclose(disparity_filter, disparity_filter.T))\n",
    "print(np.allclose(resource_allocation_weights, resource_allocation_weights.T))\n",
    "filtered_weights[resource_allocation_weights < disparity_filter] = 0\n",
    "filtered_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# check if the filtered weights are symmetric\n",
    "print(np.allclose(filtered_weights, filtered_weights.T))\n",
    "# compute the number of values which are not close to zero\n",
    "print(np.count_nonzero(~np.isclose(filtered_weights, 0))/2)\n",
    "filtered_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtered weights is not symmetric, but has inconsistent amount of edges? :()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new undirected graph with the filtered weights as adjacency matrix\n",
    "G_filtered = nx.from_numpy_array(filtered_weights)\n",
    "# reassign the node names and attributes\n",
    "G_filtered = nx.relabel_nodes(G_filtered, dict(enumerate(bipartite_one_nodes)))\n",
    "# add the attributes\n",
    "for n, d in G.nodes(data=True):\n",
    "    if d.get('bipartite') == 1:\n",
    "        # drop the bipartite attribute\n",
    "        d.pop('bipartite')\n",
    "        G_filtered.nodes[n].update(d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
